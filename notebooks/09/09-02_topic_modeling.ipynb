{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8dda7647",
      "metadata": {
        "id": "8dda7647"
      },
      "source": [
        "# Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4e312d",
      "metadata": {
        "id": "4c4e312d"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chu-ise/411A-2022/blob/main/notebooks/09/09-02_topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e5ec17",
      "metadata": {
        "id": "88e5ec17"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8fc0c1",
      "metadata": {
        "id": "6e8fc0c1"
      },
      "source": [
        "## Topic Modeling using Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdc3f72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bdc3f72",
        "outputId": "8e2f9ef3-afa5-435b-f953-b2538fd7d148"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = [\n",
        "    \"alt.atheism\",\n",
        "    \"talk.religion.misc\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "    \"comp.sys.ibm.pc.hardware\",\n",
        "    \"sci.crypt\",\n",
        "]\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\", categories=categories)\n",
        "\n",
        "print(\"#Train set size:\", len(newsgroups_train.data))\n",
        "print(\"#Selected categories:\", newsgroups_train.target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f7a323",
      "metadata": {
        "id": "d0f7a323"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(\n",
        "    token_pattern=\"[\\w']{3,}\",\n",
        "    stop_words=\"english\",\n",
        "    max_features=2000,\n",
        "    min_df=5,\n",
        "    max_df=0.5,\n",
        ")\n",
        "review_cv = cv.fit_transform(newsgroups_train.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117b78a8",
      "metadata": {
        "id": "117b78a8"
      },
      "source": [
        "### LDA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da26c423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da26c423",
        "outputId": "b4bc1fcc-5abd-458f-ea4b-3a189ddd3035"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=10,\n",
        "    max_iter=5,\n",
        "    topic_word_prior=0.1,\n",
        "    doc_topic_prior=1.0,\n",
        "    learning_method=\"online\",\n",
        "    n_jobs=-1,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "review_topics = lda.fit_transform(review_cv)\n",
        "print(\"#shape of review_topics:\", review_topics.shape)\n",
        "print(\"#Sample of review_topics:\", review_topics[0])\n",
        "\n",
        "gross_topic_weights = np.mean(review_topics, axis=0)\n",
        "print(\"#Sum of topic weights of documents:\", gross_topic_weights)\n",
        "\n",
        "print(\"#shape of topic word distribution:\", lda.components_.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3662b1ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3662b1ae",
        "outputId": "b06da3e7-a70e-4472-b13e-929d3bb2074f"
      },
      "outputs": [],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic #%d: \" % topic_idx, end=\"\")\n",
        "        print(\n",
        "            \", \".join(\n",
        "                [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n",
        "            )\n",
        "        )\n",
        "    print()\n",
        "\n",
        "\n",
        "print_top_words(lda, cv.get_feature_names_out(), 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79db881",
      "metadata": {
        "id": "b79db881"
      },
      "source": [
        "### Optimal number of topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967db96b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "967db96b",
        "outputId": "d7a2a10c-3cdd-4144-83aa-7263117024e7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_perplexity(cv, start=10, end=30, max_iter=5, topic_word_prior= 0.1, \n",
        "                    doc_topic_prior=1.0):\n",
        "    iter_num = []\n",
        "    per_value = []\n",
        "\n",
        "    for i in range(start, end + 1):\n",
        "        lda = LatentDirichletAllocation(n_components = i, max_iter=max_iter, \n",
        "                                        topic_word_prior= topic_word_prior, \n",
        "                                        doc_topic_prior=doc_topic_prior,\n",
        "                                        learning_method='batch', n_jobs= -1,\n",
        "                                        random_state=7)    \n",
        "        lda.fit(cv)\n",
        "        iter_num.append(i)\n",
        "        pv = lda.perplexity(cv)\n",
        "        per_value.append(pv)\n",
        "        print(f'n_components: {i}, perplexity: {pv:0.3f}')\n",
        "\n",
        "    plt.plot(iter_num, per_value, 'g-')\n",
        "    plt.show()\n",
        "    return start + per_value.index(min(per_value))\n",
        "\n",
        "print(\"n_components with minimum perplexity:\",\n",
        "      show_perplexity(review_cv, start=6, end=15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30ace14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e30ace14",
        "outputId": "8c39d3ad-865c-46d7-e8a2-202c87ba1135"
      },
      "outputs": [],
      "source": [
        "lda = LatentDirichletAllocation(\n",
        "    n_components=8,\n",
        "    max_iter=20,\n",
        "    topic_word_prior=0.1,\n",
        "    doc_topic_prior=1.0,\n",
        "    learning_method=\"batch\",\n",
        "    n_jobs=-1,\n",
        "    random_state=7,\n",
        ")\n",
        "\n",
        "review_topics = lda.fit_transform(review_cv)\n",
        "\n",
        "print_top_words(lda, cv.get_feature_names_out(), 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c521513b",
      "metadata": {
        "id": "c521513b"
      },
      "source": [
        "## Topic modeling using Gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e387f2f6",
      "metadata": {
        "id": "e387f2f6"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sAm8XNwdEP-w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAm8XNwdEP-w",
        "outputId": "6cb0059b-a3e6-4e5d-e076-812d28a5e1a3"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "  \n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efd2068",
      "metadata": {
        "id": "5efd2068"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
        "english_stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    tokens = RegTok.tokenize(text.lower())\n",
        "    # stopwords 제외\n",
        "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
        "    return words\n",
        "\n",
        "\n",
        "texts = [tokenizer(news) for news in newsgroups_train.data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990c82b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "990c82b5",
        "outputId": "503107b2-aceb-4ce8-a449-b7484355511c"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "dictionary = Dictionary(texts)\n",
        "print('#Number of initial unique words in documents:', len(dictionary))\n",
        "\n",
        "dictionary.filter_extremes(keep_n=2000, no_below=5, no_above=0.5)\n",
        "print('#Number of unique words after removing rare and common words:', len(dictionary))\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "print('#Number of unique tokens: %d' % len(dictionary))\n",
        "print('#Number of documents: %d' % len(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a0b12a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a0b12a5",
        "outputId": "c795c299-75d7-496c-ef64-db3729bce36f"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "num_topics = 10\n",
        "passes = 5\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    passes=passes,\n",
        "    num_topics=num_topics,\n",
        "    random_state=7,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01b0331",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c01b0331",
        "outputId": "f534afa7-8f9a-42b8-9640-71bf6988cf20"
      },
      "outputs": [],
      "source": [
        "model.print_topics(num_words=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c612bb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c612bb6",
        "outputId": "10e48fa0-ad37-4a77-b1c1-d0a5c5fddd4e"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"#topic distribution of the first document: \", model.get_document_topics(corpus)[0]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8669b5",
      "metadata": {
        "id": "5a8669b5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "    topic_table = pd.DataFrame()\n",
        "\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
        "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
        "\n",
        "        for j, (topic_num, prop_topic) in enumerate(doc):\n",
        "            if j == 0:\n",
        "                topic_table = topic_table.append(\n",
        "                    pd.Series([int(topic_num), round(prop_topic, 4), topic_list]),\n",
        "                    ignore_index=True,\n",
        "                )\n",
        "            else:\n",
        "                break\n",
        "    return topic_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f29e8d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5f29e8d5",
        "outputId": "5b6dd6ff-9ad2-4619-c7c4-9b58f0b36c38"
      },
      "outputs": [],
      "source": [
        "topictable = make_topictable_per_doc(model, corpus)\n",
        "topictable = topictable.reset_index()\n",
        "topictable.columns = ['Doc No.', 'Top topic', 'Top topic weight', 'topic weights']\n",
        "topictable.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_jB2ztXIEksO",
      "metadata": {
        "id": "_jB2ztXIEksO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91053c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "f91053c8",
        "outputId": "b9036d10-3490-4276-9f42-725103c75d83",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(model, corpus, dictionary)\n",
        "pyLDAvis.display(vis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b25285f",
      "metadata": {
        "id": "5b25285f"
      },
      "source": [
        "### Select number of topics by coherence and perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a6d982d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6d982d",
        "outputId": "a5a2ad54-caa8-4348-de70-47b19326fc5d"
      },
      "outputs": [],
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "cm = CoherenceModel(model=model, corpus=corpus, coherence=\"u_mass\")\n",
        "coherence = cm.get_coherence()\n",
        "print(coherence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748ab7e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "748ab7e4",
        "outputId": "8121ebc4-b9e7-45f3-901f-da8642e3d17d"
      },
      "outputs": [],
      "source": [
        "def show_coherence(corpus, dictionary, start=6, end=15):\n",
        "    iter_num = []\n",
        "    per_value = []\n",
        "    coh_value = []\n",
        "\n",
        "    for i in range(start, end + 1):\n",
        "        model = LdaModel(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            chunksize=1000,\n",
        "            num_topics=i,\n",
        "            random_state=7,\n",
        "        )\n",
        "        iter_num.append(i)\n",
        "        pv = model.log_perplexity(corpus)\n",
        "        per_value.append(pv)\n",
        "\n",
        "        cm = CoherenceModel(model=model, corpus=corpus, coherence=\"u_mass\")\n",
        "        cv = cm.get_coherence()\n",
        "        coh_value.append(cv)\n",
        "        print(f\"num_topics: {i}, perplexity: {pv:0.3f}, coherence: {cv:0.3f}\")\n",
        "\n",
        "    plt.plot(iter_num, per_value, \"g-\")\n",
        "    plt.xlabel(\"num_topics\")\n",
        "    plt.ylabel(\"perplexity\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(iter_num, coh_value, \"r--\")\n",
        "    plt.xlabel(\"num_topics\")\n",
        "    plt.ylabel(\"coherence\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_coherence(corpus, dictionary, start=6, end=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40a66a0f",
      "metadata": {
        "id": "40a66a0f"
      },
      "source": [
        "## Topic trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0PtjMP5aFOHH",
      "metadata": {
        "id": "0PtjMP5aFOHH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install ekorpkit[dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f16a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7f16a98",
        "outputId": "b077549b-00ee-4da6-c954-0bbc78153f2f"
      },
      "outputs": [],
      "source": [
        "from ekorpkit import eKonf\n",
        "\n",
        "cfg = eKonf.compose(config_group='corpus')\n",
        "cfg.name = 'fomc'\n",
        "cfg.data_dir = \"${cached_path:'https://github.com/entelecheia/ekorpkit-config/raw/main/data/fomc.zip',true,false}\"\n",
        "cfg.automerge = True\n",
        "fomc = eKonf.instantiate(cfg)\n",
        "print(fomc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c121a40c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c121a40c",
        "outputId": "65ab5186-b207-40fa-a7d6-0bb1cfe15aeb"
      },
      "outputs": [],
      "source": [
        "fomc_statements = fomc.data[fomc.data.content_type == 'fomc_statement'].reset_index(drop=True)\n",
        "fomc_statements['year'] = fomc_statements.timestamp.dt.year\n",
        "fomc_statements.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2b9625",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d2b9625",
        "outputId": "2351824b-4540-445a-f6a0-44f08471254a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(\n",
        "    token_pattern=\"[\\w']{3,}\",\n",
        "    stop_words=\"english\",\n",
        "    max_features=1000,\n",
        "    min_df=5,\n",
        "    max_df=0.5,\n",
        ")\n",
        "vec = cv.fit_transform(fomc_statements.text)\n",
        "print(vec.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e148bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0e148bd",
        "outputId": "2231d3e2-0491-42ee-9eb7-5b5ff20eba23"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10, n_jobs=-1, random_state=0)\n",
        "\n",
        "fomc_topics = lda.fit_transform(vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176d58a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176d58a9",
        "outputId": "ccb65c13-0f06-4028-955f-2c5dce289d29"
      },
      "outputs": [],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic #%d: \" % topic_idx, end=\"\")\n",
        "        print(\n",
        "            \", \".join(\n",
        "                [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n",
        "            )\n",
        "        )\n",
        "\n",
        "print_top_words(lda, cv.get_feature_names_out(), 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae03049",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dae03049",
        "outputId": "8ad335cf-3fd8-443a-d98d-86b0c47aa0bb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "trend_data = pd.DataFrame(fomc_topics, columns=[\"Topic\" + str(i) for i in range(1, 11)])\n",
        "trend_data = pd.concat([trend_data, fomc_statements.year], axis=1)\n",
        "trend_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9a487f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "fa9a487f",
        "outputId": "80541e01-36d9-4265-8188-a9ee7b02ec2d"
      },
      "outputs": [],
      "source": [
        "trend = trend_data.groupby(['year']).mean()\n",
        "trend.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4919c1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "f4919c1f",
        "outputId": "8e41e1a2-6e5a-4479-d970-1bb71334b2cf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(5, 2, sharex=\"col\", figsize=(12, 16))\n",
        "for col, ax in zip(trend.columns.tolist(), axes.ravel()):\n",
        "    ax.set_title(col)\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.plot(trend[col])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e472ecb4",
      "metadata": {
        "id": "e472ecb4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "08-02_topic_modeling.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f869af7787e6a1c49e09e367fc6e1b81d93d1c6583b43249c80edc047bd13cb2"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('ekonml38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
